<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
<meta name="generator" content="pdoc3 0.11.6">
<title>src.preprocessing API documentation</title>
<meta name="description" content="Image Preprocessing Module …">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/sanitize.min.css" integrity="sha512-y1dtMcuvtTMJc1yPgEqF0ZjQbhnc/bFhyvIyVNb9Zk5mIGtqVaAB1Ttl28su8AvFMOY0EwRbAe+HCLqj6W7/KA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/13.0.0/typography.min.css" integrity="sha512-Y1DYSb995BAfxobCkKepB1BqJJTPrOp3zPL74AWFugHHmmdcvO+C48WLrUOlhGMc0QG7AE3f7gmvvcrmX2fDoA==" crossorigin>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:1.5em;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:2em 0 .50em 0}h3{font-size:1.4em;margin:1.6em 0 .7em 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .2s ease-in-out}a:visited{color:#503}a:hover{color:#b62}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900;font-weight:bold}pre code{font-size:.8em;line-height:1.4em;padding:1em;display:block}code{background:#f3f3f3;font-family:"DejaVu Sans Mono",monospace;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source > summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible;min-width:max-content}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em 1em;margin:1em 0}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul ul{padding-left:1em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js" integrity="sha512-D9gUyxqja7hBtkWpPWGt9wfbfaMGVt9gnyCvYa+jojwwPHLCzUm5i8rpk7vD7wNee9bA35eYIjobYPaQuKS1MQ==" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => {
hljs.configure({languages: ['bash', 'css', 'diff', 'graphql', 'ini', 'javascript', 'json', 'plaintext', 'python', 'python-repl', 'rust', 'shell', 'sql', 'typescript', 'xml', 'yaml']});
hljs.highlightAll();
/* Collapse source docstrings */
setTimeout(() => {
[...document.querySelectorAll('.hljs.language-python > .hljs-string')]
.filter(el => el.innerHTML.length > 200 && ['"""', "'''"].includes(el.innerHTML.substring(0, 3)))
.forEach(el => {
let d = document.createElement('details');
d.classList.add('hljs-string');
d.innerHTML = '<summary>"""</summary>' + el.innerHTML.substring(3);
el.replaceWith(d);
});
}, 100);
})</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.preprocessing</code></h1>
</header>
<section id="section-intro">
<p>Image Preprocessing Module</p>
<p>Provides utilities for license plate image enhancement to improve OCR accuracy.
Includes grayscale conversion, resizing, CLAHE enhancement, and validation.</p>
<p>Main Functions:
- preprocess_plate: Main preprocessing pipeline
- resize_maintaining_aspect: Aspect ratio-preserving resize
- apply_clahe: CLAHE contrast enhancement
- validate_image: Image validation
- batch_preprocess_plates: Batch processing
- save_preprocessed_image: Save to disk
- calculate_image_stats: Statistical analysis</p>
<h2 id="note">Note</h2>
<p>Cropping functionality is in src.detection.utils.crop_detections() and should be reused.</p>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="src.preprocessing.image_enhancement" href="image_enhancement.html">src.preprocessing.image_enhancement</a></code></dt>
<dd>
<div class="desc"><p>Image Enhancement Module for License Plate Preprocessing …</p></div>
</dd>
<dt><code class="name"><a title="src.preprocessing.utils" href="utils.html">src.preprocessing.utils</a></code></dt>
<dd>
<div class="desc"><p>Preprocessing Utility Functions …</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.preprocessing.apply_clahe"><code class="name flex">
<span>def <span class="ident">apply_clahe</span></span>(<span>gray_image: numpy.ndarray,<br>clip_limit: float = 2.0,<br>grid_size: Tuple[int, int] = (8, 8)) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def apply_clahe(
    gray_image: np.ndarray, clip_limit: float = 2.0, grid_size: Tuple[int, int] = (8, 8)
) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to grayscale image.

    CLAHE enhances local contrast by dividing the image into tiles and applying
    histogram equalization to each tile with a contrast limiting threshold.
    This improves visibility of license plate text in poor lighting conditions.

    Args:
        gray_image (np.ndarray): Input grayscale image.
            Shape: (H, W). Must be single-channel uint8.
        clip_limit (float, optional): Contrast limiting threshold.
            Higher values increase contrast. Range: [1.0, 40.0]. Default: 2.0.
        grid_size (Tuple[int, int], optional): Size of grid for histogram equalization.
            Smaller tiles = more local adaptation, larger = more global.
            Default: (8, 8).

    Returns:
        np.ndarray: Enhanced grayscale image with improved local contrast.
            Shape: (H, W), dtype: uint8.

    Raises:
        ValueError: If image is not grayscale (single-channel) or not uint8.
        TypeError: If input is not a numpy array.

    Example:
        &gt;&gt;&gt; import cv2
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; # Create a low-contrast grayscale image
        &gt;&gt;&gt; img = np.random.randint(100, 150, (200, 400), dtype=np.uint8)
        &gt;&gt;&gt; enhanced = apply_clahe(img, clip_limit=3.0, grid_size=(8, 8))
        &gt;&gt;&gt; enhanced.dtype
        dtype(&#39;uint8&#39;)
        &gt;&gt;&gt; # Contrast should be improved
        &gt;&gt;&gt; np.std(enhanced) &gt; np.std(img)
        True

    Note:
        - Input must be grayscale (convert color images first)
        - clip_limit=1.0 is equivalent to standard histogram equalization
        - Typical range: 2.0-4.0 for most images
        - Smaller grid_size (e.g., 4x4) for more aggressive local adaptation
        - Larger grid_size (e.g., 16x16) for smoother global adaptation
    &#34;&#34;&#34;
    if not isinstance(gray_image, np.ndarray):
        raise TypeError(f&#34;Input must be numpy array, got {type(gray_image)}&#34;)

    if len(gray_image.shape) != 2:
        raise ValueError(f&#34;Input must be grayscale (2D array), got shape {gray_image.shape}&#34;)

    if gray_image.dtype != np.uint8:
        raise ValueError(f&#34;Input must be uint8, got {gray_image.dtype}&#34;)

    if gray_image.size == 0:
        raise ValueError(&#34;Input image is empty&#34;)

    logger.debug(f&#34;Applying CLAHE with clip_limit={clip_limit}, grid_size={grid_size}&#34;)

    # Create CLAHE object
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)

    # Apply to image
    enhanced = clahe.apply(gray_image)

    return enhanced</code></pre>
</details>
<div class="desc"><p>Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to grayscale image.</p>
<p>CLAHE enhances local contrast by dividing the image into tiles and applying
histogram equalization to each tile with a contrast limiting threshold.
This improves visibility of license plate text in poor lighting conditions.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>gray_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input grayscale image.
Shape: (H, W). Must be single-channel uint8.</dd>
<dt><strong><code>clip_limit</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Contrast limiting threshold.
Higher values increase contrast. Range: [1.0, 40.0]. Default: 2.0.</dd>
<dt><strong><code>grid_size</code></strong> :&ensp;<code>Tuple[int, int]</code>, optional</dt>
<dd>Size of grid for histogram equalization.
Smaller tiles = more local adaptation, larger = more global.
Default: (8, 8).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Enhanced grayscale image with improved local contrast.
Shape: (H, W), dtype: uint8.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If image is not grayscale (single-channel) or not uint8.</dd>
<dt><code>TypeError</code></dt>
<dd>If input is not a numpy array.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import cv2
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; # Create a low-contrast grayscale image
&gt;&gt;&gt; img = np.random.randint(100, 150, (200, 400), dtype=np.uint8)
&gt;&gt;&gt; enhanced = apply_clahe(img, clip_limit=3.0, grid_size=(8, 8))
&gt;&gt;&gt; enhanced.dtype
dtype('uint8')
&gt;&gt;&gt; # Contrast should be improved
&gt;&gt;&gt; np.std(enhanced) &gt; np.std(img)
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Input must be grayscale (convert color images first)</li>
<li>clip_limit=1.0 is equivalent to standard histogram equalization</li>
<li>Typical range: 2.0-4.0 for most images</li>
<li>Smaller grid_size (e.g., 4x4) for more aggressive local adaptation</li>
<li>Larger grid_size (e.g., 16x16) for smoother global adaptation</li>
</ul></div>
</dd>
<dt id="src.preprocessing.batch_preprocess_plates"><code class="name flex">
<span>def <span class="ident">batch_preprocess_plates</span></span>(<span>cropped_plates: List[numpy.ndarray], config: dict, validate: bool = True) ‑> List[numpy.ndarray | None]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def batch_preprocess_plates(
    cropped_plates: List[np.ndarray], config: dict, validate: bool = True
) -&gt; List[Optional[np.ndarray]]:
    &#34;&#34;&#34;
    Preprocess multiple cropped license plate images in batch.

    Applies the preprocessing pipeline to a list of cropped plate images.
    Invalid images are skipped with None returned in their position.

    Args:
        cropped_plates (List[np.ndarray]): List of cropped plate images.
        config (dict): Preprocessing configuration (same as preprocess_plate).
        validate (bool, optional): Whether to validate images before processing.
            If True, invalid images return None. Default: True.

    Returns:
        List[Optional[np.ndarray]]: List of preprocessed images.
            None values indicate images that failed validation or processing.

    Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; plates = [
        ...     np.random.randint(0, 255, (50, 150, 3), dtype=np.uint8),
        ...     np.random.randint(0, 255, (60, 180, 3), dtype=np.uint8)
        ... ]
        &gt;&gt;&gt; config = {&#39;min_width&#39;: 200, &#39;use_clahe&#39;: False}
        &gt;&gt;&gt; results = batch_preprocess_plates(plates, config)
        &gt;&gt;&gt; len(results) == len(plates)
        True
        &gt;&gt;&gt; all(r is not None for r in results)  # All valid
        True

    Note:
        - Processes images sequentially (not parallelized)
        - Logs warnings for failed images
        - Returns list with same length as input (preserves ordering)
    &#34;&#34;&#34;
    results = []

    for i, plate in enumerate(cropped_plates):
        try:
            # Validate if requested
            if validate:
                is_valid, error_msg = validate_image(plate)
                if not is_valid:
                    logger.warning(f&#34;Plate {i} failed validation: {error_msg}&#34;)
                    results.append(None)
                    continue

            # Preprocess
            preprocessed = preprocess_plate(plate, config)
            results.append(preprocessed)

        except Exception as e:
            logger.error(f&#34;Error preprocessing plate {i}: {e}&#34;)
            results.append(None)

    successful = sum(1 for r in results if r is not None)
    logger.info(f&#34;Batch preprocessing: {successful}/{len(cropped_plates)} successful&#34;)

    return results</code></pre>
</details>
<div class="desc"><p>Preprocess multiple cropped license plate images in batch.</p>
<p>Applies the preprocessing pipeline to a list of cropped plate images.
Invalid images are skipped with None returned in their position.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cropped_plates</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>List of cropped plate images.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code></dt>
<dd>Preprocessing configuration (same as preprocess_plate).</dd>
<dt><strong><code>validate</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to validate images before processing.
If True, invalid images return None. Default: True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Optional[np.ndarray]]</code></dt>
<dd>List of preprocessed images.
None values indicate images that failed validation or processing.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; plates = [
...     np.random.randint(0, 255, (50, 150, 3), dtype=np.uint8),
...     np.random.randint(0, 255, (60, 180, 3), dtype=np.uint8)
... ]
&gt;&gt;&gt; config = {'min_width': 200, 'use_clahe': False}
&gt;&gt;&gt; results = batch_preprocess_plates(plates, config)
&gt;&gt;&gt; len(results) == len(plates)
True
&gt;&gt;&gt; all(r is not None for r in results)  # All valid
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Processes images sequentially (not parallelized)</li>
<li>Logs warnings for failed images</li>
<li>Returns list with same length as input (preserves ordering)</li>
</ul></div>
</dd>
<dt id="src.preprocessing.calculate_image_stats"><code class="name flex">
<span>def <span class="ident">calculate_image_stats</span></span>(<span>image: numpy.ndarray) ‑> dict</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calculate_image_stats(image: np.ndarray) -&gt; dict:
    &#34;&#34;&#34;
    Calculate statistical properties of an image.

    Computes useful statistics for analyzing preprocessing effects:
    - Mean intensity
    - Standard deviation (contrast indicator)
    - Min/max values
    - Histogram information

    Args:
        image (np.ndarray): Input image (grayscale or color).

    Returns:
        dict: Dictionary with keys:
            - &#39;mean&#39;: Mean pixel intensity
            - &#39;std&#39;: Standard deviation (contrast)
            - &#39;min&#39;: Minimum pixel value
            - &#39;max&#39;: Maximum pixel value
            - &#39;shape&#39;: Image dimensions
            - &#39;dtype&#39;: Data type

    Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; img = np.random.randint(0, 255, (100, 200), dtype=np.uint8)
        &gt;&gt;&gt; stats = calculate_image_stats(img)
        &gt;&gt;&gt; &#39;mean&#39; in stats and &#39;std&#39; in stats
        True
        &gt;&gt;&gt; 0 &lt;= stats[&#39;mean&#39;] &lt;= 255
        True

    Note:
        - Useful for comparing before/after preprocessing
        - Higher std typically indicates better contrast
    &#34;&#34;&#34;
    stats = {
        &#34;mean&#34;: float(np.mean(image)),
        &#34;std&#34;: float(np.std(image)),
        &#34;min&#34;: int(np.min(image)),
        &#34;max&#34;: int(np.max(image)),
        &#34;shape&#34;: image.shape,
        &#34;dtype&#34;: str(image.dtype),
    }

    return stats</code></pre>
</details>
<div class="desc"><p>Calculate statistical properties of an image.</p>
<p>Computes useful statistics for analyzing preprocessing effects:
- Mean intensity
- Standard deviation (contrast indicator)
- Min/max values
- Histogram information</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input image (grayscale or color).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>Dictionary with keys:
- 'mean': Mean pixel intensity
- 'std': Standard deviation (contrast)
- 'min': Minimum pixel value
- 'max': Maximum pixel value
- 'shape': Image dimensions
- 'dtype': Data type</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; img = np.random.randint(0, 255, (100, 200), dtype=np.uint8)
&gt;&gt;&gt; stats = calculate_image_stats(img)
&gt;&gt;&gt; 'mean' in stats and 'std' in stats
True
&gt;&gt;&gt; 0 &lt;= stats['mean'] &lt;= 255
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Useful for comparing before/after preprocessing</li>
<li>Higher std typically indicates better contrast</li>
</ul></div>
</dd>
<dt id="src.preprocessing.preprocess_plate"><code class="name flex">
<span>def <span class="ident">preprocess_plate</span></span>(<span>cropped_image: numpy.ndarray, config: dict) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_plate(cropped_image: np.ndarray, config: dict) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Apply preprocessing pipeline to a cropped license plate image.

    This function applies a series of optional preprocessing steps to enhance
    license plate images for improved OCR accuracy. Steps include:
    1. Grayscale conversion (if image is color)
    2. Resizing to minimum width while maintaining aspect ratio
    3. CLAHE enhancement for improved contrast

    All steps are optional and controlled by configuration flags.

    Args:
        cropped_image (np.ndarray): Input image (cropped plate) in BGR or grayscale.
            Shape: (H, W, 3) for color or (H, W) for grayscale.
        config (dict): Preprocessing configuration with keys:
            - &#39;use_clahe&#39; (bool): Enable CLAHE enhancement
            - &#39;clahe_clip_limit&#39; (float): CLAHE clip limit (default: 2.0)
            - &#39;clahe_tile_grid_size&#39; (list): CLAHE grid size (default: [8, 8])
            - &#39;min_width&#39; (int): Minimum width in pixels (default: 200)
            - &#39;use_gaussian_blur&#39; (bool): Enable Gaussian blur (optional)
            - &#39;gaussian_kernel_size&#39; (list): Blur kernel size (optional)
            - &#39;use_sharpening&#39; (bool): Enable sharpening (optional)
            - &#39;sharpen_strength&#39; (float): Sharpening strength (optional)

    Returns:
        np.ndarray: Preprocessed image, typically grayscale.
            Shape: (H&#39;, W&#39;) where W&#39; &gt;= min_width and aspect ratio is preserved.

    Raises:
        ValueError: If input image is empty or invalid.
        TypeError: If input is not a numpy array.

    Example:
        &gt;&gt;&gt; import cv2
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; # Simulate a small cropped plate
        &gt;&gt;&gt; plate = np.random.randint(0, 255, (50, 150, 3), dtype=np.uint8)
        &gt;&gt;&gt; config = {
        ...     &#39;min_width&#39;: 200,
        ...     &#39;use_clahe&#39;: True,
        ...     &#39;clahe_clip_limit&#39;: 2.0,
        ...     &#39;clahe_tile_grid_size&#39;: [8, 8]
        ... }
        &gt;&gt;&gt; enhanced = preprocess_plate(plate, config)
        &gt;&gt;&gt; enhanced.shape[1] &gt;= 200  # Width should be at least 200
        True
        &gt;&gt;&gt; len(enhanced.shape) == 2  # Should be grayscale
        True

    Note:
        - The function creates a copy of the input to avoid modifying the original
        - Grayscale conversion is applied automatically if CLAHE is enabled
        - Optional features (blur, sharpening) are applied if enabled in config
    &#34;&#34;&#34;
    if not isinstance(cropped_image, np.ndarray):
        raise TypeError(f&#34;Input must be numpy array, got {type(cropped_image)}&#34;)

    if cropped_image.size == 0:
        raise ValueError(&#34;Input image is empty&#34;)

    # Create a copy to avoid modifying original
    image = cropped_image.copy()

    # Step 1: Convert to grayscale if needed (for CLAHE or OCR)
    # Most OCR engines work better with grayscale
    if len(image.shape) == 3:
        logger.debug(&#34;Converting BGR to grayscale&#34;)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Step 2: Resize if below minimum width (maintain aspect ratio)
    height, width = image.shape[:2]
    min_width = config.get(&#34;min_width&#34;, 200)

    if width &lt; min_width:
        logger.debug(f&#34;Resizing from width {width} to {min_width} (aspect ratio maintained)&#34;)
        image = resize_maintaining_aspect(image, min_width)

    # Step 3: Optional Gaussian blur for noise reduction
    if config.get(&#34;use_gaussian_blur&#34;, False):
        kernel_size = tuple(config.get(&#34;gaussian_kernel_size&#34;, [3, 3]))
        logger.debug(f&#34;Applying Gaussian blur with kernel {kernel_size}&#34;)
        image = cv2.GaussianBlur(image, kernel_size, 0)

    # Step 4: CLAHE enhancement (optional)
    if config.get(&#34;use_clahe&#34;, False):
        logger.debug(&#34;Applying CLAHE enhancement&#34;)
        clip_limit = config.get(&#34;clahe_clip_limit&#34;, 2.0)
        grid_size = tuple(config.get(&#34;clahe_tile_grid_size&#34;, [8, 8]))
        image = apply_clahe(image, clip_limit, grid_size)

    # Step 5: Optional sharpening
    if config.get(&#34;use_sharpening&#34;, False):
        strength = config.get(&#34;sharpen_strength&#34;, 1.0)
        logger.debug(f&#34;Applying sharpening with strength {strength}&#34;)
        # Create sharpening kernel
        kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]], dtype=np.float32)
        kernel = kernel * strength
        kernel[1, 1] = 9 - (strength - 1) * 8  # Adjust center
        image = cv2.filter2D(image, -1, kernel)

    return image</code></pre>
</details>
<div class="desc"><p>Apply preprocessing pipeline to a cropped license plate image.</p>
<p>This function applies a series of optional preprocessing steps to enhance
license plate images for improved OCR accuracy. Steps include:
1. Grayscale conversion (if image is color)
2. Resizing to minimum width while maintaining aspect ratio
3. CLAHE enhancement for improved contrast</p>
<p>All steps are optional and controlled by configuration flags.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cropped_image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input image (cropped plate) in BGR or grayscale.
Shape: (H, W, 3) for color or (H, W) for grayscale.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code></dt>
<dd>Preprocessing configuration with keys:
- 'use_clahe' (bool): Enable CLAHE enhancement
- 'clahe_clip_limit' (float): CLAHE clip limit (default: 2.0)
- 'clahe_tile_grid_size' (list): CLAHE grid size (default: [8, 8])
- 'min_width' (int): Minimum width in pixels (default: 200)
- 'use_gaussian_blur' (bool): Enable Gaussian blur (optional)
- 'gaussian_kernel_size' (list): Blur kernel size (optional)
- 'use_sharpening' (bool): Enable sharpening (optional)
- 'sharpen_strength' (float): Sharpening strength (optional)</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Preprocessed image, typically grayscale.
Shape: (H', W') where W' &gt;= min_width and aspect ratio is preserved.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If input image is empty or invalid.</dd>
<dt><code>TypeError</code></dt>
<dd>If input is not a numpy array.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import cv2
&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; # Simulate a small cropped plate
&gt;&gt;&gt; plate = np.random.randint(0, 255, (50, 150, 3), dtype=np.uint8)
&gt;&gt;&gt; config = {
...     'min_width': 200,
...     'use_clahe': True,
...     'clahe_clip_limit': 2.0,
...     'clahe_tile_grid_size': [8, 8]
... }
&gt;&gt;&gt; enhanced = preprocess_plate(plate, config)
&gt;&gt;&gt; enhanced.shape[1] &gt;= 200  # Width should be at least 200
True
&gt;&gt;&gt; len(enhanced.shape) == 2  # Should be grayscale
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>The function creates a copy of the input to avoid modifying the original</li>
<li>Grayscale conversion is applied automatically if CLAHE is enabled</li>
<li>Optional features (blur, sharpening) are applied if enabled in config</li>
</ul></div>
</dd>
<dt id="src.preprocessing.resize_maintaining_aspect"><code class="name flex">
<span>def <span class="ident">resize_maintaining_aspect</span></span>(<span>image: numpy.ndarray, target_width: int, interpolation: int = 2) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resize_maintaining_aspect(
    image: np.ndarray, target_width: int, interpolation: int = cv2.INTER_CUBIC
) -&gt; np.ndarray:
    &#34;&#34;&#34;
    Resize image to target width while maintaining aspect ratio.

    This function scales an image to a specified width while preserving
    the original aspect ratio. Uses high-quality interpolation by default.

    Args:
        image (np.ndarray): Input image (grayscale or color).
            Shape: (H, W) or (H, W, C).
        target_width (int): Desired width in pixels. Must be positive.
        interpolation (int, optional): OpenCV interpolation method.
            Default: cv2.INTER_CUBIC (high quality).
            Options: INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_LANCZOS4.

    Returns:
        np.ndarray: Resized image with target width and scaled height.
            Shape: (H&#39;, target_width) or (H&#39;, target_width, C).

    Raises:
        ValueError: If target_width &lt;= 0 or image is empty.
        TypeError: If input is not a numpy array.

    Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; # Create a 100x300 image
        &gt;&gt;&gt; img = np.random.randint(0, 255, (100, 300), dtype=np.uint8)
        &gt;&gt;&gt; resized = resize_maintaining_aspect(img, 600)
        &gt;&gt;&gt; resized.shape
        (200, 600)
        &gt;&gt;&gt; # Aspect ratio preserved: 100/300 == 200/600

    Note:
        - INTER_CUBIC is recommended for upscaling (smoother results)
        - INTER_AREA is recommended for downscaling (better quality)
        - For small images being upscaled significantly, INTER_LANCZOS4 may be better
    &#34;&#34;&#34;
    if not isinstance(image, np.ndarray):
        raise TypeError(f&#34;Input must be numpy array, got {type(image)}&#34;)

    if image.size == 0:
        raise ValueError(&#34;Input image is empty&#34;)

    if target_width &lt;= 0:
        raise ValueError(f&#34;Target width must be positive, got {target_width}&#34;)

    height, width = image.shape[:2]

    # Calculate scaling factor
    scale = target_width / width
    new_height = int(height * scale)
    new_size = (target_width, new_height)

    logger.debug(f&#34;Resizing from ({width}, {height}) to {new_size}, scale={scale:.2f}&#34;)

    # Perform resize
    resized = cv2.resize(image, new_size, interpolation=interpolation)

    return resized</code></pre>
</details>
<div class="desc"><p>Resize image to target width while maintaining aspect ratio.</p>
<p>This function scales an image to a specified width while preserving
the original aspect ratio. Uses high-quality interpolation by default.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input image (grayscale or color).
Shape: (H, W) or (H, W, C).</dd>
<dt><strong><code>target_width</code></strong> :&ensp;<code>int</code></dt>
<dd>Desired width in pixels. Must be positive.</dd>
<dt><strong><code>interpolation</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>OpenCV interpolation method.
Default: cv2.INTER_CUBIC (high quality).
Options: INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_LANCZOS4.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Resized image with target width and scaled height.
Shape: (H', target_width) or (H', target_width, C).</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If target_width &lt;= 0 or image is empty.</dd>
<dt><code>TypeError</code></dt>
<dd>If input is not a numpy array.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; # Create a 100x300 image
&gt;&gt;&gt; img = np.random.randint(0, 255, (100, 300), dtype=np.uint8)
&gt;&gt;&gt; resized = resize_maintaining_aspect(img, 600)
&gt;&gt;&gt; resized.shape
(200, 600)
&gt;&gt;&gt; # Aspect ratio preserved: 100/300 == 200/600
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>INTER_CUBIC is recommended for upscaling (smoother results)</li>
<li>INTER_AREA is recommended for downscaling (better quality)</li>
<li>For small images being upscaled significantly, INTER_LANCZOS4 may be better</li>
</ul></div>
</dd>
<dt id="src.preprocessing.save_preprocessed_image"><code class="name flex">
<span>def <span class="ident">save_preprocessed_image</span></span>(<span>image: numpy.ndarray, output_path: str, create_dirs: bool = True) ‑> bool</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_preprocessed_image(image: np.ndarray, output_path: str, create_dirs: bool = True) -&gt; bool:
    &#34;&#34;&#34;
    Save preprocessed image to disk.

    Args:
        image (np.ndarray): Preprocessed image to save.
        output_path (str): Output file path (e.g., &#39;outputs/preprocessed/plate_001.jpg&#39;).
        create_dirs (bool, optional): Whether to create parent directories if they
            don&#39;t exist. Default: True.

    Returns:
        bool: True if save was successful, False otherwise.

    Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; import tempfile
        &gt;&gt;&gt; import os
        &gt;&gt;&gt; img = np.random.randint(0, 255, (100, 200), dtype=np.uint8)
        &gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:
        ...     path = os.path.join(tmpdir, &#39;test.jpg&#39;)
        ...     success = save_preprocessed_image(img, path)
        ...     success and os.path.exists(path)
        True

    Note:
        - Supports common formats: .jpg, .png, .bmp
        - JPEG quality is set to 95 for minimal compression loss
    &#34;&#34;&#34;
    try:
        # Create directories if needed
        if create_dirs:
            output_dir = Path(output_path).parent
            output_dir.mkdir(parents=True, exist_ok=True)

        # Save image
        success = cv2.imwrite(output_path, image)

        if success:
            logger.debug(f&#34;Saved preprocessed image to {output_path}&#34;)
        else:
            logger.error(f&#34;Failed to save image to {output_path}&#34;)

        return success

    except Exception as e:
        logger.error(f&#34;Error saving image to {output_path}: {e}&#34;)
        return False</code></pre>
</details>
<div class="desc"><p>Save preprocessed image to disk.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Preprocessed image to save.</dd>
<dt><strong><code>output_path</code></strong> :&ensp;<code>str</code></dt>
<dd>Output file path (e.g., 'outputs/preprocessed/plate_001.jpg').</dd>
<dt><strong><code>create_dirs</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Whether to create parent directories if they
don't exist. Default: True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True if save was successful, False otherwise.</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; import tempfile
&gt;&gt;&gt; import os
&gt;&gt;&gt; img = np.random.randint(0, 255, (100, 200), dtype=np.uint8)
&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:
...     path = os.path.join(tmpdir, 'test.jpg')
...     success = save_preprocessed_image(img, path)
...     success and os.path.exists(path)
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>Supports common formats: .jpg, .png, .bmp</li>
<li>JPEG quality is set to 95 for minimal compression loss</li>
</ul></div>
</dd>
<dt id="src.preprocessing.validate_image"><code class="name flex">
<span>def <span class="ident">validate_image</span></span>(<span>image: numpy.ndarray,<br>min_width: int = 50,<br>min_height: int = 20,<br>max_width: int = 2000,<br>max_height: int = 1000) ‑> Tuple[bool, str]</span>
</code></dt>
<dd>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_image(
    image: np.ndarray,
    min_width: int = 50,
    min_height: int = 20,
    max_width: int = 2000,
    max_height: int = 1000,
) -&gt; Tuple[bool, str]:
    &#34;&#34;&#34;
    Validate image properties for preprocessing.

    Checks if an image meets basic requirements for license plate preprocessing:
    - Is a valid numpy array
    - Has correct dimensions (2D or 3D)
    - Has reasonable size constraints
    - Has valid data type (uint8)

    Args:
        image (np.ndarray): Input image to validate.
        min_width (int, optional): Minimum acceptable width. Default: 50.
        min_height (int, optional): Minimum acceptable height. Default: 20.
        max_width (int, optional): Maximum acceptable width. Default: 2000.
        max_height (int, optional): Maximum acceptable height. Default: 1000.

    Returns:
        Tuple[bool, str]: (is_valid, error_message)
            - is_valid: True if image passes all checks, False otherwise
            - error_message: Empty string if valid, error description if invalid

    Example:
        &gt;&gt;&gt; import numpy as np
        &gt;&gt;&gt; valid_img = np.random.randint(0, 255, (100, 200, 3), dtype=np.uint8)
        &gt;&gt;&gt; is_valid, msg = validate_image(valid_img)
        &gt;&gt;&gt; is_valid
        True
        &gt;&gt;&gt; msg
        &#39;&#39;
        &gt;&gt;&gt;
        &gt;&gt;&gt; invalid_img = np.random.randint(0, 255, (10, 20), dtype=np.uint8)
        &gt;&gt;&gt; is_valid, msg = validate_image(invalid_img)
        &gt;&gt;&gt; is_valid
        False
        &gt;&gt;&gt; &#39;height&#39; in msg.lower()
        True

    Note:
        - GTA V plates are typically 200-400px wide when cropped
        - Validation prevents processing of invalid or corrupted crops
    &#34;&#34;&#34;
    # Type check
    if not isinstance(image, np.ndarray):
        return False, f&#34;Image must be numpy array, got {type(image)}&#34;

    # Empty check
    if image.size == 0:
        return False, &#34;Image is empty&#34;

    # Dimension check
    if len(image.shape) not in [2, 3]:
        return False, f&#34;Image must be 2D or 3D array, got shape {image.shape}&#34;

    # Color channel check
    if len(image.shape) == 3 and image.shape[2] not in [1, 3, 4]:
        return False, f&#34;Invalid number of channels: {image.shape[2]}&#34;

    # Data type check
    if image.dtype != np.uint8:
        return False, f&#34;Image must be uint8, got {image.dtype}&#34;

    # Size constraints
    height, width = image.shape[:2]

    if width &lt; min_width:
        return False, f&#34;Width {width} below minimum {min_width}&#34;

    if height &lt; min_height:
        return False, f&#34;Height {height} below minimum {min_height}&#34;

    if width &gt; max_width:
        return False, f&#34;Width {width} exceeds maximum {max_width}&#34;

    if height &gt; max_height:
        return False, f&#34;Height {height} exceeds maximum {max_height}&#34;

    return True, &#34;&#34;</code></pre>
</details>
<div class="desc"><p>Validate image properties for preprocessing.</p>
<p>Checks if an image meets basic requirements for license plate preprocessing:
- Is a valid numpy array
- Has correct dimensions (2D or 3D)
- Has reasonable size constraints
- Has valid data type (uint8)</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Input image to validate.</dd>
<dt><strong><code>min_width</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Minimum acceptable width. Default: 50.</dd>
<dt><strong><code>min_height</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Minimum acceptable height. Default: 20.</dd>
<dt><strong><code>max_width</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum acceptable width. Default: 2000.</dd>
<dt><strong><code>max_height</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Maximum acceptable height. Default: 1000.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[bool, str]</code></dt>
<dd>(is_valid, error_message)
- is_valid: True if image passes all checks, False otherwise
- error_message: Empty string if valid, error description if invalid</dd>
</dl>
<h2 id="example">Example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; valid_img = np.random.randint(0, 255, (100, 200, 3), dtype=np.uint8)
&gt;&gt;&gt; is_valid, msg = validate_image(valid_img)
&gt;&gt;&gt; is_valid
True
&gt;&gt;&gt; msg
''
&gt;&gt;&gt;
&gt;&gt;&gt; invalid_img = np.random.randint(0, 255, (10, 20), dtype=np.uint8)
&gt;&gt;&gt; is_valid, msg = validate_image(invalid_img)
&gt;&gt;&gt; is_valid
False
&gt;&gt;&gt; 'height' in msg.lower()
True
</code></pre>
<h2 id="note">Note</h2>
<ul>
<li>GTA V plates are typically 200-400px wide when cropped</li>
<li>Validation prevents processing of invalid or corrupted crops</li>
</ul></div>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src" href="../index.html">src</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="src.preprocessing.image_enhancement" href="image_enhancement.html">src.preprocessing.image_enhancement</a></code></li>
<li><code><a title="src.preprocessing.utils" href="utils.html">src.preprocessing.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.preprocessing.apply_clahe" href="#src.preprocessing.apply_clahe">apply_clahe</a></code></li>
<li><code><a title="src.preprocessing.batch_preprocess_plates" href="#src.preprocessing.batch_preprocess_plates">batch_preprocess_plates</a></code></li>
<li><code><a title="src.preprocessing.calculate_image_stats" href="#src.preprocessing.calculate_image_stats">calculate_image_stats</a></code></li>
<li><code><a title="src.preprocessing.preprocess_plate" href="#src.preprocessing.preprocess_plate">preprocess_plate</a></code></li>
<li><code><a title="src.preprocessing.resize_maintaining_aspect" href="#src.preprocessing.resize_maintaining_aspect">resize_maintaining_aspect</a></code></li>
<li><code><a title="src.preprocessing.save_preprocessed_image" href="#src.preprocessing.save_preprocessed_image">save_preprocessed_image</a></code></li>
<li><code><a title="src.preprocessing.validate_image" href="#src.preprocessing.validate_image">validate_image</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.11.6</a>.</p>
</footer>
</body>
</html>
