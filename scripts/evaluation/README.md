# Evaluation Scripts

Commands and utilities for scoring detection results, generating reports,
and visualising model performance.

- `evaluate_detection.py`: Computes precision/recall metrics across
	validation runs and surfaces per-condition breakdowns.
- `generate_evaluation_report.py`: Produces a markdown/HTML summary of
	evaluation outputs for quick sharing.
- `visualize_detection_results.py`: Generates charts showing detection
	rates, confidence trends, and dataset composition.
